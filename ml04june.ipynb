{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlSWxm5PNGurNLexpER/Z6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Parul30163/python/blob/main/ml04june.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_Ca82u0PUOp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from  tensorflow.keras  import datasets ,layers , models\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "UcTBJr9oTyPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load and split Datasets\n",
        "\n",
        "(train_images ,train_labels),(test_images ,test_labels)=datasets.cifar10.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHxx6inHUGFo",
        "outputId": "4f564aae-b1e2-4a09-dc5a-211f9e62c724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 6s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize  pixel value to be between 0 and  1\n",
        "train_images ,test_images=train_images/255.0 ,test_images/255.0"
      ],
      "metadata": {
        "id": "rhYEypsfUau_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names =['airplane' ,'automobile','bird','cat','deer','dog' , 'frog','horse','ship','truck']"
      ],
      "metadata": {
        "id": "AOiVkOM-Uo-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lets look at a one image . we change this to look at other images ( img_index= 1,2,3....)\n",
        "IMG_INDEX=1\n",
        "plt.imshow(train_images[IMG_INDEX],cmap=plt.cm.binary)\n",
        "plt.xlabel(class_names[train_labels[IMG_INDEX][0]])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "l0rVZxVdU4Nc",
        "outputId": "28b17733-a992-4b5e-e1fd-55bd5a26aefe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGwCAYAAADv4LHCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAdrUlEQVR4nO3dfWyV9f3/8dcB2iNIe6BQelqhWEBhirCtQj1BGZHKjc5x9wcyE8skGLCQAd7WBFCzpQSXOdyYLjORLAo4zCrRBLyptMxZcFQJwlhHSRk1tEVJep1SbGHt5/fHvp7fjrRA21PePeX5SD4JPdfVc96XV9Kn55yrpz7nnBMAAFdZH+sBAADXJgIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYKKf9QDf1draqlOnTikpKUk+n896HABABznn1NDQoIyMDPXp0/7znB4XoFOnTmnEiBHWYwAAuqi6ulrDhw9vd3uPewkuKSnJegQAQAxc7ud5twVo8+bNuvHGG3XdddcpJydHn3766RV9Hy+7AUDvcLmf590SoDfffFNr1qzR+vXr9dlnn2nixImaOXOmTp8+3R0PBwCIR64bTJ482eXn50e+bmlpcRkZGa6wsPCy3+t5npPEYrFYrDhfnudd8ud9zJ8BnT9/XuXl5crNzY3c1qdPH+Xm5qqsrOyi/ZubmxUOh6MWAKD3i3mAvv76a7W0tCgtLS3q9rS0NNXW1l60f2FhoQKBQGRxBRwAXBvMr4IrKCiQ53mRVV1dbT0SAOAqiPnvAQ0dOlR9+/ZVXV1d1O11dXUKBoMX7e/3++X3+2M9BgCgh4v5M6DExERlZ2eruLg4cltra6uKi4sVCoVi/XAAgDjVLZ+EsGbNGuXl5en222/X5MmT9Zvf/EaNjY362c9+1h0PBwCIQ90SoIULF+qrr77SunXrVFtbq+9///vavXv3RRcmAACuXT7nnLMe4n+Fw2EFAgHrMQAAXeR5npKTk9vdbn4VHADg2kSAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATMQ8QM8++6x8Pl/UGjduXKwfBgAQ5/p1x53eeuut+vDDD///g/TrlocBAMSxbilDv379FAwGu+OuAQC9RLe8B3Ts2DFlZGRo1KhRevDBB3Xy5Ml2921ublY4HI5aAIDeL+YBysnJ0ZYtW7R79269/PLLqqqq0l133aWGhoY29y8sLFQgEIisESNGxHokAEAP5HPOue58gPr6eo0cOVK//vWvtWTJkou2Nzc3q7m5OfJ1OBwmQgDQC3iep+Tk5Ha3d/vVAYMGDdLNN9+sysrKNrf7/X75/f7uHgMA0MN0++8BnT17VsePH1d6enp3PxQAII7EPECPP/64SktLdeLECX3yySeaN2+e+vbtq0WLFsX6oQAAcSzmL8F9+eWXWrRokc6cOaPU1FTdeeed2rdvn1JTU2P9UACAONbtFyF0VDgcViAQsB4DANBFl7sIgc+CAwCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmOhygvXv36v7771dGRoZ8Pp/efvvtqO3OOa1bt07p6enq37+/cnNzdezYsVjNCwDoJTocoMbGRk2cOFGbN29uc/vGjRv10ksv6ZVXXtH+/ft1/fXXa+bMmWpqaurysACAXsR1gSRXVFQU+bq1tdUFg0H3wgsvRG6rr693fr/fbdu2rc37aGpqcp7nRVZ1dbWTxGKxWKw4X57nXbIhMX0PqKqqSrW1tcrNzY3cFggElJOTo7Kysja/p7CwUIFAILJGjBgRy5EAAD1UTANUW1srSUpLS4u6PS0tLbLtuwoKCuR5XmRVV1fHciQAQA/Vz3oAv98vv99vPQYA4CqL6TOgYDAoSaqrq4u6va6uLrINAAApxgHKyspSMBhUcXFx5LZwOKz9+/crFArF8qEAAHGuwy/BnT17VpWVlZGvq6qqdPDgQaWkpCgzM1OrVq3SL37xC910003KysrS2rVrlZGRoblz58ZybgBAvOvopdd79uxp83K7vLy8yKXYa9eudWlpac7v97vp06e7ioqKK75/z/PMLx1ksVgsVtfX5S7D9jnnnHqQcDisQCBgPQYAoIs8z1NycnK72/ksOACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgosMB2rt3r+6//35lZGTI5/Pp7bffjtq+ePFi+Xy+qDVr1qxYzQsA6CU6HKDGxkZNnDhRmzdvbnefWbNmqaamJrK2bdvWpSEBAL1Pv45+w+zZszV79uxL7uP3+xUMBq/o/pqbm9Xc3Bz5OhwOd3QkAEAc6pb3gEpKSjRs2DCNHTtWy5cv15kzZ9rdt7CwUIFAILJGjBjRHSMBAHoYn3POdfqbfT4VFRVp7ty5kdu2b9+uAQMGKCsrS8ePH9czzzyjgQMHqqysTH379r3oPtp6BkSEACD+eZ6n5OTkdrd3+CW4y3nggQci/77ttts0YcIEjR49WiUlJZo+ffpF+/v9fvn9/liPAQDo4br9MuxRo0Zp6NChqqys7O6HAgDEkW4P0JdffqkzZ84oPT29ux8KABBHOvwS3NmzZ6OezVRVVengwYNKSUlRSkqKnnvuOS1YsEDBYFDHjx/Xk08+qTFjxmjmzJkxHRwAEOdcB+3Zs8dJumjl5eW5c+fOuRkzZrjU1FSXkJDgRo4c6ZYuXepqa2uv+P49z2vz/lksFosVX8vzvEv+vO/SVXDdIRwOKxAIWI8BAOiiy10Fx2fBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmOhQgAoLCzVp0iQlJSVp2LBhmjt3rioqKqL2aWpqUn5+voYMGaKBAwdqwYIFqquri+nQAID416EAlZaWKj8/X/v27dMHH3ygCxcuaMaMGWpsbIzss3r1ar3zzjvasWOHSktLderUKc2fPz/mgwMA4pzrgtOnTztJrrS01DnnXH19vUtISHA7duyI7HP06FEnyZWVlV3RfXqe5ySxWCwWK86X53mX/HnfpfeAPM+TJKWkpEiSysvLdeHCBeXm5kb2GTdunDIzM1VWVtbmfTQ3NyscDkctAEDv1+kAtba2atWqVZoyZYrGjx8vSaqtrVViYqIGDRoUtW9aWppqa2vbvJ/CwkIFAoHIGjFiRGdHAgDEkU4HKD8/X4cPH9b27du7NEBBQYE8z4us6urqLt0fACA+9OvMN61YsULvvvuu9u7dq+HDh0duDwaDOn/+vOrr66OeBdXV1SkYDLZ5X36/X36/vzNjAADiWIeeATnntGLFChUVFemjjz5SVlZW1Pbs7GwlJCSouLg4cltFRYVOnjypUCgUm4kBAL1Ch54B5efna+vWrdq5c6eSkpIi7+sEAgH1799fgUBAS5Ys0Zo1a5SSkqLk5GStXLlSoVBId9xxR7ccAAAgTnXksmu1c6nda6+9Ftnnm2++cY8++qgbPHiwGzBggJs3b56rqam54sfgMmwWi8XqHetyl2H7/i8sPUY4HFYgELAeAwDQRZ7nKTk5ud3tfBYcAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADDRoQAVFhZq0qRJSkpK0rBhwzR37lxVVFRE7TNt2jT5fL6otWzZspgODQCIfx0KUGlpqfLz87Vv3z598MEHunDhgmbMmKHGxsao/ZYuXaqamprI2rhxY0yHBgDEv34d2Xn37t1RX2/ZskXDhg1TeXm5pk6dGrl9wIABCgaDsZkQANArdek9IM/zJEkpKSlRt7/xxhsaOnSoxo8fr4KCAp07d67d+2hublY4HI5aAIBrgOuklpYWd99997kpU6ZE3f6HP/zB7d692x06dMi9/vrr7oYbbnDz5s1r937Wr1/vJLFYLBarly3P8y7ZkU4HaNmyZW7kyJGuurr6kvsVFxc7Sa6ysrLN7U1NTc7zvMiqrq42/4/GYrFYrK6vywWoQ+8BfWvFihV69913tXfvXg0fPvyS++bk5EiSKisrNXr06Iu2+/1++f3+zowBAIhjHQqQc04rV65UUVGRSkpKlJWVddnvOXjwoCQpPT29UwMCAHqnDgUoPz9fW7du1c6dO5WUlKTa2lpJUiAQUP/+/XX8+HFt3bpV9957r4YMGaJDhw5p9erVmjp1qiZMmNAtBwAAiFMded9H7bzO99prrznnnDt58qSbOnWqS0lJcX6/340ZM8Y98cQTl30d8H95nmf+uiWLxWKxur4u97Pf939h6THC4bACgYD1GACALvI8T8nJye1u57PgAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAICJDgXo5Zdf1oQJE5ScnKzk5GSFQiHt2rUrsr2pqUn5+fkaMmSIBg4cqAULFqiuri7mQwMA4l+HAjR8+HBt2LBB5eXlOnDggO6++27NmTNHR44ckSStXr1a77zzjnbs2KHS0lKdOnVK8+fP75bBAQBxznXR4MGD3auvvurq6+tdQkKC27FjR2Tb0aNHnSRXVlbW7vc3NTU5z/Miq7q62klisVgsVpwvz/Mu2Y9OvwfU0tKi7du3q7GxUaFQSOXl5bpw4YJyc3Mj+4wbN06ZmZkqKytr934KCwsVCAQia8SIEZ0dCQAQRzocoC+++EIDBw6U3+/XsmXLVFRUpFtuuUW1tbVKTEzUoEGDovZPS0tTbW1tu/dXUFAgz/Miq7q6usMHAQCIP/06+g1jx47VwYMH5Xme3nrrLeXl5am0tLTTA/j9fvn9/k5/PwAgPnU4QImJiRozZowkKTs7W3//+9+1adMmLVy4UOfPn1d9fX3Us6C6ujoFg8GYDQwA6B26/HtAra2tam5uVnZ2thISElRcXBzZVlFRoZMnTyoUCnX1YQAAvUyHngEVFBRo9uzZyszMVENDg7Zu3aqSkhK99957CgQCWrJkidasWaOUlBQlJydr5cqVCoVCuuOOO7prfgBAnOpQgE6fPq2HHnpINTU1CgQCmjBhgt577z3dc889kqQXX3xRffr00YIFC9Tc3KyZM2fq97//fbcMDgCIbz7nnLMe4n+Fw2EFAgHrMQAAXeR5npKTk9vdzmfBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATPS4APWwD2YAAHTS5X6e97gANTQ0WI8AAIiBy/0873GfBdfa2qpTp04pKSlJPp8vcns4HNaIESNUXV19yc8WinccZ+9xLRyjxHH2NrE4TuecGhoalJGRoT592n+e0+E/SNfd+vTpo+HDh7e7PTk5uVef/G9xnL3HtXCMEsfZ23T1OK/kQ6V73EtwAIBrAwECAJiImwD5/X6tX79efr/fepRuxXH2HtfCMUocZ29zNY+zx12EAAC4NsTNMyAAQO9CgAAAJggQAMAEAQIAmIibAG3evFk33nijrrvuOuXk5OjTTz+1Himmnn32Wfl8vqg1btw467G6ZO/evbr//vuVkZEhn8+nt99+O2q7c07r1q1Tenq6+vfvr9zcXB07dsxm2C643HEuXrz4onM7a9Ysm2E7qbCwUJMmTVJSUpKGDRumuXPnqqKiImqfpqYm5efna8iQIRo4cKAWLFiguro6o4k750qOc9q0aRedz2XLlhlN3Dkvv/yyJkyYEPll01AopF27dkW2X61zGRcBevPNN7VmzRqtX79en332mSZOnKiZM2fq9OnT1qPF1K233qqamprI+vjjj61H6pLGxkZNnDhRmzdvbnP7xo0b9dJLL+mVV17R/v37df3112vmzJlqamq6ypN2zeWOU5JmzZoVdW63bdt2FSfsutLSUuXn52vfvn364IMPdOHCBc2YMUONjY2RfVavXq133nlHO3bsUGlpqU6dOqX58+cbTt1xV3KckrR06dKo87lx40ajiTtn+PDh2rBhg8rLy3XgwAHdfffdmjNnjo4cOSLpKp5LFwcmT57s8vPzI1+3tLS4jIwMV1hYaDhVbK1fv95NnDjReoxuI8kVFRVFvm5tbXXBYNC98MILkdvq6+ud3+9327ZtM5gwNr57nM45l5eX5+bMmWMyT3c5ffq0k+RKS0udc/89dwkJCW7Hjh2RfY4ePeokubKyMqsxu+y7x+mccz/60Y/cz3/+c7uhusngwYPdq6++elXPZY9/BnT+/HmVl5crNzc3clufPn2Um5ursrIyw8li79ixY8rIyNCoUaP04IMP6uTJk9YjdZuqqirV1tZGnddAIKCcnJxed14lqaSkRMOGDdPYsWO1fPlynTlzxnqkLvE8T5KUkpIiSSovL9eFCxeizue4ceOUmZkZ1+fzu8f5rTfeeENDhw7V+PHjVVBQoHPnzlmMFxMtLS3avn27GhsbFQqFruq57HEfRvpdX3/9tVpaWpSWlhZ1e1pamv75z38aTRV7OTk52rJli8aOHauamho999xzuuuuu3T48GElJSVZjxdztbW1ktTmef12W28xa9YszZ8/X1lZWTp+/LieeeYZzZ49W2VlZerbt6/1eB3W2tqqVatWacqUKRo/fryk/57PxMREDRo0KGrfeD6fbR2nJP30pz/VyJEjlZGRoUOHDumpp55SRUWF/vKXvxhO23FffPGFQqGQmpqaNHDgQBUVFemWW27RwYMHr9q57PEBulbMnj078u8JEyYoJydHI0eO1J///GctWbLEcDJ01QMPPBD592233aYJEyZo9OjRKikp0fTp0w0n65z8/HwdPnw47t+jvJz2jvORRx6J/Pu2225Tenq6pk+fruPHj2v06NFXe8xOGzt2rA4ePCjP8/TWW28pLy9PpaWlV3WGHv8S3NChQ9W3b9+LrsCoq6tTMBg0mqr7DRo0SDfffLMqKyutR+kW3567a+28StKoUaM0dOjQuDy3K1as0Lvvvqs9e/ZE/dmUYDCo8+fPq76+Pmr/eD2f7R1nW3JyciQp7s5nYmKixowZo+zsbBUWFmrixInatGnTVT2XPT5AiYmJys7OVnFxceS21tZWFRcXKxQKGU7Wvc6ePavjx48rPT3depRukZWVpWAwGHVew+Gw9u/f36vPqyR9+eWXOnPmTFydW+ecVqxYoaKiIn300UfKysqK2p6dna2EhISo81lRUaGTJ0/G1fm83HG25eDBg5IUV+ezLa2trWpubr665zKmlzR0k+3btzu/3++2bNni/vGPf7hHHnnEDRo0yNXW1lqPFjOPPfaYKykpcVVVVe5vf/uby83NdUOHDnWnT5+2Hq3TGhoa3Oeff+4+//xzJ8n9+te/dp9//rn797//7ZxzbsOGDW7QoEFu586d7tChQ27OnDkuKyvLffPNN8aTd8yljrOhocE9/vjjrqyszFVVVbkPP/zQ/fCHP3Q33XSTa2pqsh79ii1fvtwFAgFXUlLiampqIuvcuXORfZYtW+YyMzPdRx995A4cOOBCoZALhUKGU3fc5Y6zsrLSPf/88+7AgQOuqqrK7dy5040aNcpNnTrVePKOefrpp11paamrqqpyhw4dck8//bTz+Xzu/fffd85dvXMZFwFyzrnf/va3LjMz0yUmJrrJkye7ffv2WY8UUwsXLnTp6ekuMTHR3XDDDW7hwoWusrLSeqwu2bNnj5N00crLy3PO/fdS7LVr17q0tDTn9/vd9OnTXUVFhe3QnXCp4zx37pybMWOGS01NdQkJCW7kyJFu6dKlcfc/T20dnyT32muvRfb55ptv3KOPPuoGDx7sBgwY4ObNm+dqamrshu6Eyx3nyZMn3dSpU11KSorz+/1uzJgx7oknnnCe59kO3kEPP/ywGzlypEtMTHSpqalu+vTpkfg4d/XOJX+OAQBgose/BwQA6J0IEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAgB7sxIkT8vl8kc8bA3oTAgR0wrRp07Rq1SrrMYC4RoCAbuCc03/+8x/rMYAejQABHbR48WKVlpZq06ZN8vl88vl82rJli3w+n3bt2qXs7Gz5/X59/PHHWrx4sebOnRv1/atWrdK0adMiX7e2tmrjxo0aM2aM/H6/MjMz9ctf/rLNx25padHDDz+scePG9eo/2Y5rA38RFeigTZs26V//+pfGjx+v559/XpJ05MgRSdLTTz+tX/3qVxo1apQGDx58RfdXUFCgP/7xj3rxxRd15513qqamps0/N9/c3KxFixbpxIkT+utf/6rU1NTYHRRggAABHRQIBJSYmKgBAwZE/kLkt8F4/vnndc8991zxfTU0NGjTpk363e9+p7y8PEnS6NGjdeedd0btd/bsWd13331qbm7Wnj17FAgEYnQ0gB1eggNi6Pbbb+/Q/kePHlVzc7OmT59+yf0WLVqkxsZGvf/++8QHvQYBAmLo+uuvj/q6T58++u6f3Lpw4ULk3/3797+i+7333nt16NAhlZWVdX1IoIcgQEAnJCYmqqWl5bL7paamqqamJuq2//2dnptuukn9+/dXcXHxJe9n+fLl2rBhg37yk5+otLS0UzMDPQ3vAQGdcOONN2r//v06ceKEBg4cqNbW1jb3u/vuu/XCCy/oT3/6k0KhkF5//XUdPnxYP/jBDyRJ1113nZ566ik9+eSTSkxM1JQpU/TVV1/pyJEjWrJkSdR9rVy5Ui0tLfrxj3+sXbt2XfQ+ERBveAYEdMLjjz+uvn376pZbblFqamq7l0TPnDlTa9eu1ZNPPqlJkyapoaFBDz30UNQ+a9eu1WOPPaZ169bpe9/7nhYuXKjTp0+3eX+rVq3Sc889p3vvvVeffPJJzI8LuJp87rsvUAMAcBXwDAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAICJ/wcsd3kg+fKD+QAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model =models.Sequential()\n",
        "model.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(32,32,3)))\n",
        "model.add(layers.MaxPooling2D((2,2))) # this layer will perform the max pooling operation using 2x2 samples and a\n",
        "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(64,(3,3),activation='relu'))"
      ],
      "metadata": {
        "id": "k4XSijNxVaet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary() # lets have a look at our model so far"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27evwDZYXDfm",
        "outputId": "e98501e1-f5f4-4ee4-e821-72953383a9fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 15, 15, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 6, 6, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 4, 4, 64)          36928     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 56320 (220.00 KB)\n",
            "Trainable params: 56320 (220.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(layers.Flatten())\n",
        "#convert high D. data into 1D data\n",
        "#we need to take these extracted features and add a way to classify them.\n",
        "#this is why we add the layers to our model.\n",
        "model.add(layers.Dense(64,activation='relu'))\n",
        "model.add(layers.Dense(10))"
      ],
      "metadata": {
        "id": "neFZ4j6eXIsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eu23fyNRX17P",
        "outputId": "542c26af-e1c5-4f0e-c244-8b2cc73e0dc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 15, 15, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 6, 6, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 4, 4, 64)          36928     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                65600     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 122570 (478.79 KB)\n",
            "Trainable params: 122570 (478.79 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can se the flatten layer changes the shape of our data so that we can feed it ti the 64 nodes dence layer,\n",
        "#followed by the final output layers,  followed by the final output layers of 10 neurones ( one of each class)"
      ],
      "metadata": {
        "id": "npug9fBnX4p8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now we will train and compile the model  using the recimmanded hyperparameter from tenserflow\n",
        "model.compile(optimizer='adam', loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics =['accuracy'])"
      ],
      "metadata": {
        "id": "wBT-v2YZYeMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_images,train_labels,epochs=10,validation_data=(test_images,test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "sLQxkVZ3ZAyv",
        "outputId": "c96b1021-cd3b-4304-84fd-631e6526a7f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1479/1563 [===========================>..] - ETA: 2s - loss: 2.3028 - accuracy: 0.0974"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-409beff8db15>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train on 50000 sample and validate on 10000 samples."
      ],
      "metadata": {
        "id": "bNg6035RZjGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model ==> we can determine how well the model performed by looking at its performnce on the test data set"
      ],
      "metadata": {
        "id": "sF6dUf8qZz-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss , test_acc =model.evaluate(test_images,test_labels,verbose=2)\n",
        "print(test_acc)"
      ],
      "metadata": {
        "id": "_IgYxjwWaDX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# in this model we get our accuracy ~ 70%. This is okay but surely there is a way to improve on this by pretained model and fine tuning.\n",
        "\n"
      ],
      "metadata": {
        "id": "OR4jS_EiaLnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-trained Models and Fine tunning ==>\n",
        "\n",
        "#a pre-trained model is a machine learning model that has been trained on a large dataset to perform a\n",
        "#specific task,\n"
      ],
      "metadata": {
        "id": "t3lAi0mnZqx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FsRIP0FfaFdI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}